{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from transformers import BertModel\n",
    "from gslTranslater.constants import *\n",
    "from gslTranslater.utils.common import read_yaml, create_directories\n",
    "from gslTranslater.components.sign_language_translator import SignLanguageTranslator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_learning_rate: float\n",
    "    params_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath=CONFIG_FILE_PATH, \n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        training_data = Path(training.training_data_dir)\n",
    "        create_directories([Path(training.root_dir)])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=self.params.EPOCHS,\n",
    "            params_batch_size=self.params.BATCH_SIZE,\n",
    "            params_learning_rate=self.params.LEARNING_RATE,\n",
    "            params_image_size=self.params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = SignLanguageTranslator(\n",
    "            cnn_model=models.resnet50(pretrained=False),\n",
    "            transformer_model=BertModel.from_pretrained('nlpaueb/bert-base-greek-uncased-v1'),\n",
    "            tokenizer_len=None\n",
    "        )\n",
    "        self.model.load_state_dict(torch.load(self.config.updated_base_model_path))\n",
    "        self.model.train()\n",
    "\n",
    "    def train_valid_loader(self):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(self.config.params_image_size[:-1]),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        train_dataset = datasets.ImageFolder(root=self.config.training_data / \"Train\", transform=transform)\n",
    "        valid_dataset = datasets.ImageFolder(root=self.config.training_data / \"Test\", transform=transform)\n",
    "\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=self.config.params_batch_size, shuffle=True)\n",
    "        self.valid_loader = DataLoader(valid_dataset, batch_size=self.config.params_batch_size, shuffle=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: nn.Module):\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "    def train(self):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.config.params_learning_rate)\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        for epoch in range(self.config.params_epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            for images, labels in self.train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{self.config.params_epochs}, Loss: {running_loss / len(self.train_loader)}\")\n",
    "\n",
    "            # Validation phase\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in self.valid_loader:\n",
    "                    outputs = self.model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            val_loss /= len(self.valid_loader)\n",
    "            print(f\"Validation Loss after Epoch {epoch + 1}: {val_loss}\")\n",
    "\n",
    "            # Checkpoint: Save the model if it has the best validation loss so far\n",
    "            if val_loss < best_val_loss:\n",
    "                print(f\"Validation loss improved from {best_val_loss} to {val_loss}. Saving checkpoint...\")\n",
    "                best_val_loss = val_loss\n",
    "                self.save_model(path=self.config.trained_model_path, model=self.model)\n",
    "\n",
    "        print(\"Training completed. Best validation loss was:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_loader()\n",
    "    training.train()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
