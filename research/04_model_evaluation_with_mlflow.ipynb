{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import dagshub\n",
    "import tensorflow as tf\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gslTranslater.utils.common import read_yaml, create_directories, save_json\n",
    "from gslTranslater.constants import *\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Dev\\\\Upwork\\\\GSL\\\\GSL-Project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    root_dir: Path\n",
    "    path_of_model: Path\n",
    "    test_csv: Path\n",
    "    mlflow_uri: str\n",
    "    dagshub_username: str\n",
    "    dagshub_repo_name: str\n",
    "    max_seq_length: int\n",
    "    image_size: list\n",
    "    batch_size: int\n",
    "    all_params: dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath=CONFIG_FILE_PATH, \n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        evaluation = self.config.evaluation\n",
    "        data_ingestion = self.config.data_ingestion\n",
    "        return EvaluationConfig(\n",
    "            root_dir=Path(data_ingestion.data_dir),\n",
    "            path_of_model=Path(self.config.training.trained_model_path),\n",
    "            test_csv=Path(data_ingestion.test_csv),\n",
    "            mlflow_uri=evaluation.mlflow_uri,\n",
    "            dagshub_username=evaluation.dagshub_username,\n",
    "            dagshub_repo_name=evaluation.dagshub_repo_name,\n",
    "            max_seq_length=self.params.MAX_SEQ_LENGTH,\n",
    "            image_size=self.params.IMAGE_SIZE,\n",
    "            batch_size=self.params.BATCH_SIZE,\n",
    "            all_params=self.params\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self, csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Filter for the selected unique words\n",
    "        df = df[df['Gloss'].isin(df['Gloss'].unique()[:self.config.all_params['NUM_UNIQUE_WORDS']])]\n",
    "\n",
    "        # Ensure we're selecting only one instance per word\n",
    "        df = df.groupby('Gloss').head(1).reset_index(drop=True)\n",
    "\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            frames_path = os.path.join(self.config.root_dir, row['Path'])\n",
    "            frames = sorted([os.path.join(frames_path, img) for img in os.listdir(frames_path) if img.endswith('.jpg')])\n",
    "\n",
    "            sequence = []\n",
    "            for frame in frames:\n",
    "                image = tf.keras.preprocessing.image.load_img(frame, target_size=tuple(self.config.image_size[:-1]))\n",
    "                image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "                image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "                sequence.append(image)\n",
    "\n",
    "            data.append(sequence)\n",
    "            labels.append(row['Gloss'])\n",
    "\n",
    "        # Pad sequences to ensure uniform shape\n",
    "        data = tf.keras.preprocessing.sequence.pad_sequences(data, maxlen=self.config.max_seq_length, padding='post', dtype='float32')\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        return data, labels\n",
    "\n",
    "    def encode_labels(self, labels):\n",
    "        label_encoder = LabelEncoder()\n",
    "        labels = label_encoder.fit_transform(labels)\n",
    "        labels = torch.tensor(labels)\n",
    "        labels = nn.functional.one_hot(labels, num_classes=len(np.unique(labels))).float()\n",
    "        return labels\n",
    "\n",
    "    def load_model(self, path: Path):\n",
    "        self.model = tf.keras.models.load_model(path)\n",
    "        # No need to call self.model.eval() in TensorFlow/Keras\n",
    "\n",
    "    def evaluate(self):\n",
    "        # Load and preprocess the data using TensorFlow/Keras\n",
    "        test_data, test_labels = self.load_data(self.config.test_csv)\n",
    "\n",
    "        # Encode labels using TensorFlow/Keras utilities\n",
    "        label_encoder = LabelEncoder()\n",
    "        test_labels = label_encoder.fit_transform(test_labels)\n",
    "        test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=len(np.unique(test_labels)))\n",
    "\n",
    "        # Perform predictions using the Keras model\n",
    "        predictions = self.model.predict(test_data)\n",
    "\n",
    "        # Calculate loss and accuracy using TensorFlow/Keras\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(test_labels, predictions)\n",
    "        accuracy = tf.keras.metrics.CategoricalAccuracy()(test_labels, predictions)\n",
    "\n",
    "        avg_loss = loss.numpy()\n",
    "        avg_accuracy = accuracy.numpy()\n",
    "\n",
    "        print(f'Test Loss: {avg_loss}, Test Accuracy: {avg_accuracy * 100:.2f}%')\n",
    "\n",
    "        return avg_loss, avg_accuracy\n",
    "\n",
    "\n",
    "    def save_score(self, avg_loss, avg_accuracy):\n",
    "        # Convert TensorFlow/PyTorch float32 to standard Python float\n",
    "        scores = {\n",
    "            \"loss\": float(avg_loss),  # Convert to float\n",
    "            \"accuracy\": float(avg_accuracy)  # Convert to float\n",
    "        }\n",
    "        save_json(path=Path(\"scores.json\"), data=scores)\n",
    "\n",
    "\n",
    "    def log_into_mlflow(self, avg_loss, avg_accuracy):\n",
    "        dagshub.init(repo_owner=self.config.dagshub_username, repo_name=self.config.dagshub_repo_name, mlflow=True)\n",
    "        mlflow.set_tracking_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics({\"test_loss\": avg_loss, \"test_accuracy\": avg_accuracy})\n",
    "\n",
    "            # Register the model if not using a file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "                mlflow.tensorflow.log_model(self.model, \"model\", registered_model_name=\"CNN_LSTM_Model\")\n",
    "            else:\n",
    "                mlflow.tensorflow.log_model(self.model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    evaluation_config = config.get_evaluation_config()\n",
    "    model_evaluation = Evaluation(config=evaluation_config)\n",
    "    model_evaluation.load_model(evaluation_config.path_of_model)\n",
    "    avg_loss, avg_accuracy = model_evaluation.evaluate()\n",
    "    model_evaluation.save_score(avg_loss, avg_accuracy)\n",
    "    model_evaluation.log_into_mlflow(avg_loss, avg_accuracy)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
