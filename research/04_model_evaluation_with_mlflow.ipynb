{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import dagshub\n",
    "import tensorflow as tf\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gslTranslater.utils.common import read_yaml, create_directories, save_json\n",
    "from gslTranslater.constants import *\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Dev\\\\Upwork\\\\GSL\\\\GSL-Project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    root_dir: Path\n",
    "    path_of_model: Path\n",
    "    test_csv: Path\n",
    "    mlflow_uri: str\n",
    "    dagshub_username: str\n",
    "    dagshub_repo_name: str\n",
    "    max_seq_length: int\n",
    "    image_size: list\n",
    "    batch_size: int\n",
    "    all_params: dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath=CONFIG_FILE_PATH, \n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        evaluation = self.config.evaluation\n",
    "        data_ingestion = self.config.data_ingestion\n",
    "        return EvaluationConfig(\n",
    "            root_dir=Path(data_ingestion.data_dir),\n",
    "            path_of_model=Path(self.config.training.trained_model_path),\n",
    "            test_csv=Path(data_ingestion.test_csv),\n",
    "            mlflow_uri=evaluation.mlflow_uri,\n",
    "            dagshub_username=evaluation.dagshub_username,\n",
    "            dagshub_repo_name=evaluation.dagshub_repo_name,\n",
    "            max_seq_length=self.params.MAX_SEQ_LENGTH,\n",
    "            image_size=self.params.IMAGE_SIZE,\n",
    "            batch_size=self.params.BATCH_SIZE,\n",
    "            all_params=self.params\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self, csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Filter for the selected unique words\n",
    "        df = df[df['Gloss'].isin(df['Gloss'].unique()[:self.config.all_params['NUM_UNIQUE_WORDS']])]\n",
    "\n",
    "        # Ensure we're selecting only one instance per word\n",
    "        df = df.groupby('Gloss').head(1).reset_index(drop=True)\n",
    "\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            frames_path = os.path.join(self.config.root_dir, row['Path'])\n",
    "            frames = sorted([os.path.join(frames_path, img) for img in os.listdir(frames_path) if img.endswith('.jpg')])\n",
    "\n",
    "            sequence = []\n",
    "            for frame in frames:\n",
    "                image = tf.keras.preprocessing.image.load_img(frame, target_size=tuple(self.config.image_size[:-1]))\n",
    "                image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "                image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "                sequence.append(image)\n",
    "\n",
    "            data.append(sequence)\n",
    "            labels.append(row['Gloss'])\n",
    "\n",
    "        # Pad sequences to ensure uniform shape\n",
    "        data = tf.keras.preprocessing.sequence.pad_sequences(data, maxlen=self.config.max_seq_length, padding='post', dtype='float32')\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        return data, labels\n",
    "\n",
    "    def encode_labels(self, labels):\n",
    "        label_encoder = LabelEncoder()\n",
    "        labels = label_encoder.fit_transform(labels)\n",
    "        labels = torch.tensor(labels)\n",
    "        labels = nn.functional.one_hot(labels, num_classes=len(np.unique(labels))).float()\n",
    "        return labels\n",
    "\n",
    "    def load_model(self, path: Path):\n",
    "        self.model = tf.keras.models.load_model(path)\n",
    "        # No need to call self.model.eval() in TensorFlow/Keras\n",
    "\n",
    "    def evaluate(self):\n",
    "        # Load and preprocess the data using TensorFlow/Keras\n",
    "        test_data, test_labels = self.load_data(self.config.test_csv)\n",
    "\n",
    "        # Encode labels using TensorFlow/Keras utilities\n",
    "        label_encoder = LabelEncoder()\n",
    "        test_labels = label_encoder.fit_transform(test_labels)\n",
    "        test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=len(np.unique(test_labels)))\n",
    "\n",
    "        # Perform predictions using the Keras model\n",
    "        predictions = self.model.predict(test_data)\n",
    "\n",
    "        # Calculate loss and accuracy using TensorFlow/Keras\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(test_labels, predictions)\n",
    "        accuracy = tf.keras.metrics.CategoricalAccuracy()(test_labels, predictions)\n",
    "\n",
    "        avg_loss = loss.numpy()\n",
    "        avg_accuracy = accuracy.numpy()\n",
    "\n",
    "        print(f'Test Loss: {avg_loss}, Test Accuracy: {avg_accuracy * 100:.2f}%')\n",
    "\n",
    "        return avg_loss, avg_accuracy\n",
    "\n",
    "\n",
    "    def save_score(self, avg_loss, avg_accuracy):\n",
    "        # Convert TensorFlow/PyTorch float32 to standard Python float\n",
    "        scores = {\n",
    "            \"loss\": float(avg_loss),  # Convert to float\n",
    "            \"accuracy\": float(avg_accuracy)  # Convert to float\n",
    "        }\n",
    "        save_json(path=Path(\"scores.json\"), data=scores)\n",
    "\n",
    "\n",
    "    def log_into_mlflow(self, avg_loss, avg_accuracy):\n",
    "        dagshub.init(repo_owner=self.config.dagshub_username, repo_name=self.config.dagshub_repo_name, mlflow=True)\n",
    "        mlflow.set_tracking_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics({\"test_loss\": avg_loss, \"test_accuracy\": avg_accuracy})\n",
    "\n",
    "            # Register the model if not using a file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "                mlflow.tensorflow.log_model(self.model, \"model\", registered_model_name=\"CNN_LSTM_Model\")\n",
    "            else:\n",
    "                mlflow.tensorflow.log_model(self.model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-30 15:29:23,872: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-08-30 15:29:23,872: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-08-30 15:29:23,888: INFO: common: created directory at: artifacts]\n",
      "1/1 [==============================] - 64s 64s/step\n",
      "Test Loss: 13.029507637023926, Test Accuracy: 4.00%\n",
      "[2024-08-30 15:30:45,160: INFO: common: json file saved at: scores.json]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"calvinsendawula/GSL-Project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"calvinsendawula/GSL-Project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-30 15:30:46,194: INFO: helpers: Initialized MLflow to track repo \"calvinsendawula/GSL-Project\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository calvinsendawula/GSL-Project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository calvinsendawula/GSL-Project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-30 15:30:46,194: INFO: helpers: Repository calvinsendawula/GSL-Project initialized!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/30 15:30:50 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-30 15:31:11,874: WARNING: save: Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ALIENW~1\\AppData\\Local\\Temp\\tmprffzlm52\\model\\data\\model\\assets\n",
      "[2024-08-30 15:31:19,010: INFO: builder_impl: Assets written to: C:\\Users\\ALIENW~1\\AppData\\Local\\Temp\\tmprffzlm52\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'CNN_LSTM_Model'.\n",
      "2024/08/30 15:36:51 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: CNN_LSTM_Model, version 1\n",
      "Created version '1' of model 'CNN_LSTM_Model'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    evaluation_config = config.get_evaluation_config()\n",
    "    model_evaluation = Evaluation(config=evaluation_config)\n",
    "    model_evaluation.load_model(evaluation_config.path_of_model)\n",
    "    avg_loss, avg_accuracy = model_evaluation.evaluate()\n",
    "    model_evaluation.save_score(avg_loss, avg_accuracy)\n",
    "    model_evaluation.log_into_mlflow(avg_loss, avg_accuracy)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
